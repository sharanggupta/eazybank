# Default values for EazyBank Observability Stack
# Override in environments/dev|staging|prod/values.yaml

# Global namespace for all observability components
namespace: otel

# Enable/disable entire stack
enabled: true

# Whether to create the namespace (set to false if kubectl creates it first)
createNamespace: false

# Prometheus Configuration
prometheus:
  enabled: true
  image:
    repository: prom/prometheus
    tag: v2.52.0
    pullPolicy: IfNotPresent

  replicas: 1

  storage:
    size: 2Gi
    storageClassName: ""
    retentionDays: 1

  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  service:
    type: ClusterIP
    port: 9090
    annotations: {}

  scrapeInterval: 30s
  evaluationInterval: 30s

# Grafana Configuration
grafana:
  enabled: true
  image:
    repository: grafana/grafana
    tag: "11.0.0"
    pullPolicy: IfNotPresent

  replicas: 1

  storage:
    size: 1Gi
    storageClassName: ""

  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "256Mi"
      cpu: "200m"

  service:
    type: NodePort
    port: 3000
    nodePort: 30030
    annotations: {}

  admin:
    username: admin
    password: admin  # Change in production!
    existingSecret: ""
    existingSecretPasswordKey: "admin-password"

  # Default datasources
  datasources:
    prometheus:
      enabled: true
      url: http://prometheus:9090
    loki:
      enabled: true
      url: http://loki:3100
    tempo:
      enabled: true
      url: http://tempo:3200

# Loki Configuration
loki:
  enabled: true
  image:
    repository: grafana/loki
    tag: "2.8.0"
    pullPolicy: IfNotPresent

  replicas: 1

  storage:
    size: 5Gi
    storageClassName: ""
    retentionDays: 7

  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  service:
    type: ClusterIP
    port: 3100
    annotations: {}

# Tempo Configuration
tempo:
  enabled: true
  image:
    repository: grafana/tempo
    tag: "2.3.1"
    pullPolicy: IfNotPresent

  replicas: 1

  storage:
    size: 5Gi
    storageClassName: ""
    retentionDays: 7

  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  service:
    type: ClusterIP
    ports:
      otlp: 4318  # OTLP HTTP receiver
      prometheus: 3200  # Prometheus metrics

# OpenTelemetry Collector Configuration
otelCollector:
  enabled: true
  image:
    repository: otel/opentelemetry-collector-contrib
    tag: "0.97.0"
    pullPolicy: IfNotPresent

  replicas: 2

  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"

  service:
    type: ClusterIP
    ports:
      otlpHttp: 4318
      prometheus: 8889
    annotations: {}

  # Configuration embedded as ConfigMap
  config:
    receivers:
      otlp:
        protocols:
          http:
            endpoint: 0.0.0.0:4318
          grpc:
            endpoint: 0.0.0.0:4317


    processors:
      batch:
        send_batch_size: 100
        timeout: 10s

    exporters:
      logging:
        loglevel: debug
      otlphttp/tempo:
        endpoint: http://tempo:4318
      prometheus:
        endpoint: "0.0.0.0:8889"

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [logging, otlphttp/tempo]
        metrics:
          receivers: [otlp]
          processors: [batch]
          exporters: [prometheus]

# Grafana Alloy Configuration (log collector)
alloy:
  enabled: true
  image:
    repository: grafana/alloy
    tag: "v1.0.0"
    pullPolicy: IfNotPresent

  # DaemonSet (one per node)
  deploymentType: daemonset

  resources:
    requests:
      memory: "128Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"

  # Configuration embedded as ConfigMap
  config: |
    // Discover Kubernetes pods
    discovery.kubernetes "pods" {
      role = "pod"
    }

    // Scrape logs from Kubernetes pods (EazyBank services)
    loki.source.kubernetes "pods" {
      targets    = discovery.kubernetes.pods.targets
      forward_to = [loki.relabel.services.receiver]
    }

    // Relabel to only include EazyBank services
    loki.relabel "services" {
      forward_to = [loki.process.parse_json.receiver]

      rule {
        source_labels = ["__meta_kubernetes_namespace"]
        target_label  = "namespace"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_name"]
        target_label  = "pod"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_label_app"]
        target_label  = "app"
      }
    }

    // Parse JSON logs and extract labels
    loki.process "parse_json" {
      forward_to = [loki.write.local.receiver]

      stage.json {
        expressions = {
          level      = "level",
          service    = "service",
          timestamp  = "timestamp",
          message    = "message",
          logger     = "logger",
          thread     = "thread",
          trace_id   = "traceId",
          span_id    = "spanId",
        }
      }

      stage.labels {
        values = {
          level   = "",
        }
      }

      stage.timestamp {
        source = "timestamp"
        format = "RFC3339Nano"
        fallback_formats = ["2006-01-02T15:04:05.999Z", "2006-01-02T15:04:05Z07:00"]
      }

      stage.output {
        source = "message"
      }
    }

    // Write logs to Loki
    loki.write "local" {
      endpoint {
        url = "http://loki:3100/loki/api/v1/push"
      }
    }

  # Use nodeName from env for host volume mount (required for Docker socket)
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "12345"

# Ingress Configuration (for production Grafana access)
ingress:
  enabled: false
  className: "nginx"
  annotations: {}
  host: grafana.eazybank.com
  path: /
  tls: []

# Persistence Configuration
persistence:
  storageClass: ""
  # Leave empty for default storage class
